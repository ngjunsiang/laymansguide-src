<!DOCTYPE html>
<html lang="en">
<head>
          <title>Layman's Guide to Computing - Issue 140: The shared memory dream</title>
        <meta charset="utf-8" />
        <meta name="generator" content="Pelican" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" type="text/css" href="/theme/css/style.css" />




    <meta name="tags" content="memory" />

</head>

<body>
        <header>
              <hgroup><h1><a href="/">Layman's Guide to Computing</a></h1></hgroup>
        <nav><ul>
            <li><a href="/categories">Seasons</a></li>
            <li><a href="/tags">Tags</a></li>
        </ul></nav>
        </header>
        <main>
<article>
  <p><a href="/category/season-11.html">Season 11</a></p>
  <header>
    <h2>
      <a href="/issue140.html" rel="bookmark"
         title="Permalink to Issue 140: The shared memory dream">Issue 140: The shared memory dream</a></h2>
 
  </header>
  <p>Published: <time datetime="2021-10-02T08:00:00+08:00">
    Sat 02 October 2021
  </time></p>
  <p><a href="https://buttondown.email/laymansguide/archive/"><strong>Previously:</strong></a> Around 2015, the high-performance computer industry quickly realised that this would be much more efficient if the CPU and GPU could <em>share the same memory</em>. This idea was labelled heterogeneous systems architecture (HSA).</p>
<p>Let‚Äôs rewind a bit further from last issue. That was in 2015.</p>
<p>Circa 2009, changes were happening on the desktop motherboard, as the memory controller hub (MCH) came on-board the CPU to reduce latency when communicating with memory (<a href="/issue134.html">Issues 134</a>)‚Äì<a href="/issue135.html">135</a>)). But the memory chips themselves remained on the motherboard, and this was the case even in 2018, in Apple‚Äôs Macbook Air (<a href="/issue136.html">Issue 136</a>)).</p>
<h2>Bringing memory on-board</h2>
<p>Smartphones can‚Äôt afford to do that; every bit of mainboard space is precious! The Apple A-series processors have been gradually moving more and more memory into the CPU, where it enjoys lower latency communicating with the CPU.</p>
<p>In 2013, Apple released the iPhone 5S, using the Apple A7 SoC. This was Apple‚Äôs first 64-bit SoC (<a href="/issue055.html">Issue 55</a>)), and by this point Apple had managed to bring 1GB of memory onto the SoC package. By 2018, With the Apple A12 SoC, the on-board memory had increased up to 4GB on high-end iPhone X models.</p>
<p>So in 2015, the high-performance folks (working with workstations and servers) were dreaming of the CPU and GPU sharing memory, while from 2013, in smartphones, the CPU, GPU, and system memory were already cohabiting in the same chip package! CPU, GPU, and memory all living in the same space ‚Ä¶ how does this work?</p>
<h2>Memory: yours or mine?</h2>
<p>Remember this diagram?</p>
<p><img alt="Chipset diagram of ATX systems for Intel Core (i-Series)" src="/issue134_02.gif"><br>
<em>An Intel Core i-series ATX system chipset diagram.<br />The MCH is merged into the CPU, but still a discrete unit.<br />DDR refers to computer memory, while GDDR refers to graphics card memory (<a href="/issue123.html">Issue123</a>))<br />Source: <a href="https://arstechnica.com/gadgets/2009/09/intel-launches-all-new-pc-architecture-with-core-i5i7-cpus/">Ars</a></em>    </p>
<p>Apple is pretty tight-lipped about the technical details of its products, but if the industry standard is anything to go by, the GPU will usually have its own memory, separate from the CPU.</p>
<p>After all, CPUs and GPUs don‚Äôt do the same work, or even work the same way (<a href="/issue123.html">Issue 123</a>)). They use different memory, they use memory differently, they store data differently, and if they accidentally overwrote each other‚Äôs data ‚Ä¶ well, your device would just crash.</p>
<p>So ‚Ä¶ that on-board memory, whose is it? CPU‚Äôs, or GPU‚Äôs?</p>
<h2>Successful sharing looks like ...</h2>
<p>One thing that makes it difficult to share memory is that the CPU and GPU have to ‚Äúspeak the same language‚Äù; they need a common shared understanding of the workflow involved in passing data through shared memory.</p>
<p>This is easier to develop when a single company has control over both CPU and GPU designs. This is not always the case; many smartphones have CPU designs from one company and GPU designs from another!</p>
<p>For instance, the Apple A-series processors initially used GPUs from a graphics company called Imagination Technologies, designed by their PowerVR division. With a CPU and GPU from different teams, working in different ways, shared memory is not likely to happen<sup id="fnref:1"><a class="footnote-ref" href="#fn:1">1</a></sup>.</p>
<p>But in the A10 SoC, released in 2016, Apple had subtly started to replace parts of the GPU with their own in-house designs. The A10 would be the last in the line of the ‚ÄúFusion‚Äù SoC series.</p>
<p>When the A11 SoC was released in late 2017‚Äîfirst in the ‚ÄúBionic‚Äù series of SoCs‚ÄîPowerVR‚Äôs GPU had been replaced by Apple‚Äôs own design<sup id="fnref:2"><a class="footnote-ref" href="#fn:2">2</a></sup>.</p>
<p>Apple is finally in the position of working towards shared memory with their Bionic-series SoCs, with the A14 being the fourth ‚ÄúBionic‚Äù SoC.</p>
<p><strong>Issue summary:</strong> Shared memory is easier to implement when a company has control over the designs of both CPU and GPU.</p>
<p>The story which began in <a href="/issue138.html">Issue 138</a>) is coming to a close soon! Next issue, the curtain falls, the A14 and M1 are released, and Apple (probably) pulls the chip industry in a new direction again.</p>
<h2>What I‚Äôll be covering next</h2>
<p><strong>Next issue:</strong> [LMG S10] Issue 141: The Apple A14 and M1</p>
<p>And finally I can geek out over the A14 and M1 üòé don't worry, I‚Äôll keep it on-topic.</p>
<p><strong>Sometime in the future:</strong> What is:</p>
<ul>
<li>XSS? [Issue 8]</li>
<li>a good reason developers write code and give it away for free online? [Issue 21]</li>
<li>OpenType? And what are fonts anyway? [Issue 42]</li>
</ul>
<div class="footnote">
<hr>
<ol>
<li id="fn:1">
<p>What about other companies that had control over the CPU and GPU designs? Such as AMD, Samsung, Qualcomm, ...? It‚Äôs a long story, and not really suitable for a layman newsletter. Sorry.&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:2">
<p>The design is technically Apple‚Äôs, but they had been learning from many generations of working with PowerVR‚Äôs GPU, so the early initial designs are very likely heavily influenced by it.&#160;<a class="footnote-backref" href="#fnref:2" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
</ol>
</div>
  <footer>
    <!--     <p>Last updated: <time datetime="2021-10-02T08:00:00+08:00">
      Sat 02 October 2021
    </time></p>
 -->
    <address>
      By           <a href="/author/j-s-ng.html">J S Ng</a>
    </address>
    <p>
        Tags:
            <a href="/tag/memory.html">memory</a>
    </p>
  </footer>
  </article>
<ul>
        <li>
            <a href="/issue139.html">
                Issue 139: What‚Äôs before this line is mine, what‚Äôs after this line is yours
            </a>
        </li>
        <li>
            <a href="/issue141.html">
                Issue 141: The Apple A14 and M1
            </a>
        </li>
</ul>
        </main>
        <footer>
                <address>
                Proudly powered by <a rel="nofollow" href="https://getpelican.com/">Pelican</a>,
                which takes great advantage of <a rel="nofollow" href="https://www.python.org/">Python</a>.
                </address>
        </footer>
</body>
</html>